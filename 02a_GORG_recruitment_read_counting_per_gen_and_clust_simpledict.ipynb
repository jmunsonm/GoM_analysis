{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "April 9th 2021 Jacob copied this notebook from what Julia had previously done to redo this using the GTDB classification results.\n",
    "\n",
    "### This notebook takes ~15 hours to run with 32 CPUs and 64G of memory. \n",
    "It should be run via a screen session on charlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convoluted description of task\n",
    "\n",
    "Basically, the 6th column () contains all of the best matches if there are multiple best matches. As long as all of these contigs/SAGs are assigned to the same Genus I can go ahead and classify that read as originating from that Genus. Otherwise, it is of ambiguous origin and I can not assign it to that Genus. I need some assistance in figuring out how to parse the outputs from the DNA and RNA recruitments so that instead of just looking at the Genus (the last column) it looks at the Genus, the contigs that are in the 6th column and confirms that all of the SAGs with contigs are part of that Genus. I have skimmed a couple of the output files and there are defiantly some examples of reads that have best matches to multiple SAGs like the example below from this file /mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations/All_190709_GoM_RNA_seq_bbmerge_reads_annotated_classified2.txt. \n",
    "\n",
    "The genus by data csv file is not sufficient for this. For each date I need a csv file that is a grid of the gene name (prokka_gene) by genus. That way I can differentiate expression between different genes at different time points sorry for this omission I completely spaced on that earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to use\n",
    "Right now there are 2 sets of recruitment that I need to do this on. The transcriptomic \\*annotated.txt files in this folder /mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations\n",
    "\n",
    "And the DNA recruitment \\*annotated.txt files that you previously created the read_counting notebook to process in this folder /mnt/scgc/simon/microg2p/analyses/GORG_recruitment/201130_GORG_DNA_recruitment/results/annotations\n",
    "\n",
    "This file should contain all of the SAGs as well as the Genus that they are assigned to /mnt/scgc/simon/microg2p/analyses/ani/All_GoM_SAGs_1cell_20kb_decon_clusters_added.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "* Count reads recruited to each gene name + functional description per Genus, \n",
    "* Separate count by whether read recruited exclusively to given Genus, or recruited to several Genera (aka shared with other genera).  \n",
    "* Count reads recruited per Genus, per functional category, per metagenome.\n",
    "\n",
    "The plan:\n",
    "* Dataframe per metagenome will have the columns: ['gene_id','GEN','Exclusive','Shared'], \n",
    "* Include ec_number and prokka functions as well\n",
    "* 'Exclusive' and 'Shared' columns will be read counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import math\n",
    "import os \n",
    "from collections import Counter\n",
    "\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "\n",
    "def safe_makedir(dname):\n",
    "    \"\"\"\n",
    "    Make a directory if it doesn't exist, handling concurrent race conditions.\n",
    "    \"\"\"\n",
    "    if not dname:\n",
    "        return dname\n",
    "    num_tries = 0\n",
    "    max_tries = 5\n",
    "    while not os.path.exists(dname):\n",
    "        try:\n",
    "            os.makedirs(dname)\n",
    "        except OSError:\n",
    "            if num_tries > max_tries:\n",
    "                raise\n",
    "            num_tries += 1\n",
    "            time.sleep(2)\n",
    "    return dname\n",
    "\n",
    "read_files = glob.glob('/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations/*annotated.txt') + \\\n",
    "glob.glob('/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/201130_GORG_DNA_recruitment/results/annotations/*annotated.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations/All_171102_GoM_RNA_seq_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations/All_181030_GoM_RNA_seq_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations/All_190402_GoM_RNA_seq_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/no_GEN/GEN_SAGs/results/annotations/All_190709_GoM_RNA_seq_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/201130_GORG_DNA_recruitment/results/annotations/ALL_20171102_contf_pe_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/201130_GORG_DNA_recruitment/results/annotations/ALL_20181030_contf_pe_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/201130_GORG_DNA_recruitment/results/annotations/ALL_20190402_contf_pe_bbmerge_reads_annotated.txt',\n",
       " '/mnt/scgc/simon/microg2p/analyses/GORG_recruitment/201130_GORG_DNA_recruitment/results/annotations/ALL_20190709_contf_pe_bbmerge_reads_annotated.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buliding a master dataframe of all GoM ORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file that indicates which sags belong to which category\n",
    "\n",
    "cat_file = '/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/Summary_files/All_GoM_SAGs_1cell_20kb_decon_531normalized_predresp_rate_GTDBclass.csv'\n",
    "namecolumnid = 'name'\n",
    "categorycolumnid = 'GTDB_classification'\n",
    "\n",
    "#catdf_file = '/mnt/scgc/simon/microg2p/analyses/ani/All_GoM_SAGs_1cell_20kb_decon_clusters_added.csv'\n",
    "catdf = pd.read_csv(cat_file)\n",
    "\n",
    "\n",
    "gadict = {l[namecolumnid]:l[categorycolumnid] for i, l in catdf.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmseqs_cluster_file = '/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210325_GoM_recluster_analysis/mmseqs/analyses/GoM_sag_orfs_80minid_m80.tsv'\n",
    "\n",
    "head = ['gene_cluster_rep', 'gene']\n",
    "gcdf = pd.read_csv(mmseqs_cluster_file,\n",
    "                         sep='\\t', names=head)\n",
    "\n",
    "gcdf['gene_cluster_rep'] = [\"_\".join(i.split(\"_\")[:-1]) for i in gcdf['gene_cluster_rep']]\n",
    "gcdf['gene'] = [\"_\".join(i.split(\"_\")[:-1]) for i in gcdf['gene']]\n",
    "\n",
    "#gcdict = {}\n",
    "#gcdict = {l['gene']:l['gene_cluster_rep'] for i, l in gcdf.iterrows()}\n",
    "### Use the gadict from above to check if genes are part of multiple genera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exclusive', 3471051), ('shared', 156770), ('unclassified_only', 36836)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcdf['gene_sag'] = [i.split(\"_\")[0] for i in gcdf['gene']]\n",
    "gcdf['gene_genus'] = [gadict[i] for i in gcdf['gene_sag']]\n",
    "\n",
    "# this counts the number of genes represented in each gene cluster\n",
    "genus_per_cluster = gcdf[gcdf['gene_genus'] != 'Unclassified'].drop_duplicates(subset=['gene_cluster_rep','gene_genus']).groupby('gene_cluster_rep', as_index=False)['gene'].count().rename(columns={'gene':'genus_count'})\n",
    "\n",
    "genus_per_cluster['gene_cluster_genus_status'] = ['exclusive' if i == 1 else 'shared' for i in genus_per_cluster['genus_count']]\n",
    "gcdf2 = gcdf.merge(genus_per_cluster[['gene_cluster_rep','gene_cluster_genus_status']], how='left')\n",
    "\n",
    "gcdf2['gene_cluster_genus_status'] = gcdf2['gene_cluster_genus_status'].fillna('unclassified_only')\n",
    "\n",
    "\n",
    "\n",
    "Counter(gcdf2['gene_cluster_genus_status']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_cluster_rep</th>\n",
       "      <th>gene</th>\n",
       "      <th>gene_sag</th>\n",
       "      <th>gene_genus</th>\n",
       "      <th>gene_cluster_genus_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AH-704-O17_NODE_7;76986;77843</td>\n",
       "      <td>AH-704-O17_NODE_7;76986;77843</td>\n",
       "      <td>AH-704-O17</td>\n",
       "      <td>Akkermansiaceae</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AH-704-O17_NODE_7;76986;77843</td>\n",
       "      <td>AH-704-K03_NODE_40;1572;2429</td>\n",
       "      <td>AH-704-K03</td>\n",
       "      <td>Akkermansiaceae</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AH-704-O17_NODE_7;76986;77843</td>\n",
       "      <td>AH-707-F08_NODE_84;3340;4197</td>\n",
       "      <td>AH-707-F08</td>\n",
       "      <td>Akkermansiaceae</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AH-704-O17_NODE_7;76986;77843</td>\n",
       "      <td>AH-707-K14_NODE_54;1628;2485</td>\n",
       "      <td>AH-707-K14</td>\n",
       "      <td>Akkermansiaceae</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AH-704-O17_NODE_7;76986;77843</td>\n",
       "      <td>AH-707-B03_NODE_10;6131;6988</td>\n",
       "      <td>AH-707-B03</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>exclusive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gene_cluster_rep                           gene    gene_sag  \\\n",
       "0  AH-704-O17_NODE_7;76986;77843  AH-704-O17_NODE_7;76986;77843  AH-704-O17   \n",
       "1  AH-704-O17_NODE_7;76986;77843   AH-704-K03_NODE_40;1572;2429  AH-704-K03   \n",
       "2  AH-704-O17_NODE_7;76986;77843   AH-707-F08_NODE_84;3340;4197  AH-707-F08   \n",
       "3  AH-704-O17_NODE_7;76986;77843   AH-707-K14_NODE_54;1628;2485  AH-707-K14   \n",
       "4  AH-704-O17_NODE_7;76986;77843   AH-707-B03_NODE_10;6131;6988  AH-707-B03   \n",
       "\n",
       "        gene_genus gene_cluster_genus_status  \n",
       "0  Akkermansiaceae                 exclusive  \n",
       "1  Akkermansiaceae                 exclusive  \n",
       "2  Akkermansiaceae                 exclusive  \n",
       "3  Akkermansiaceae                 exclusive  \n",
       "4     Unclassified                 exclusive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcdf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcdf2['gene_cluster-gene_genus'] = ['{}-{}'.format(l['gene_cluster_rep'],l['gene_genus']) for i, l in gcdf2.iterrows()]\n",
    "gcdf2.to_csv(\"/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210325_GoM_recluster_analysis/mmseqs/analyses/GoM_sag_orfs_80minid_m80_gtdb_added.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above step, you can submit the qsub for the \\*simpledict.py script, but before you do that, if you've made changes to the above table, you will want to go into that script and change the intermediate destination directory.  I've done that for the changes made on 7/20/21... the new intermediate output directory is: ```/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210720_GoM_recluster_analysis/GORG_recruitment_mmseq_clusts```\n",
    "\n",
    "\n",
    "Below is just development scripting that does not need to be run if you run the associated python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = {l['gene']:'{}--{}'.format(l['gene_cluster_rep'],l['gene_genus']) for i, l in gcdf2.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are adding an additional piece of information the output files separated by genera.  We will add the gene cluster(s) associated with each gene hit in a new column.  If so, write that gene cluster id to the intermediate output file. Whether or not the gene cluster is shared or exclusive can be determined by merging the table we created above to the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\tsequence_id\ttaxonomy_id\tlength\ttaxonomy_ids_lca\tsequence_ids_lca\tprotein_sequence\ttaxonomic_lineage\tec_number\tprokka_function\tprokka_gene\tgen\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:22109:16099\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:9934:16106\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:25787:16120\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:16339:16127\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:18264:16134\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:10785:16139\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:21840:16156\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:11213:16159\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:21896:16164\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:15055:16174\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:25331:16177\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:10181:16186\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "C\tNB501011:101:HYFW5AFXY:1:11101:13771:16204\t126\t110\t126,\tAH-707-M18_NODE_75;2531;2986,\tPEEGGDDVKSSWPLCLGLHTSYN,\tBacteria; Planctomycetes; Planctomycetia; Planctomycetales; Planctomycetaceae; NA; NA;\t.\thypothetical_protein\t.\t64\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:17019:16205\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:4918:16210\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "C\tNB501011:101:HYFW5AFXY:1:11101:1936:16211\t31989\t76\t31989,\tAH-545-P07_NODE_108;1019;1612,\tPTAASRRSLGRVSVPV,\tBacteria; Proteobacteria; Alphaproteobacteria; Rhodobacterales; Rhodobacteraceae; NA; NA;\t1.8.5.-\tProtein-methionine-sulfoxide_reductase_catalytic_subunit_MsrP\tmsrP\t9\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:1479:16216\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "U\tNB501011:101:HYFW5AFXY:1:11101:5242:16223\t0\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "C\tNB501011:101:HYFW5AFXY:1:11101:6115:16226\t1648490\t106\t1648490,\tAH-704-A20_NODE_67;1343;1486,\tAGANALSEPPGKYGRKTKTQRN,\tBacteria; Verrucomicrobia; Verrucomicrobiae; Verrucomicrobiales; Rubritaleaceae; NA; NA;\t.\thypothetical_protein\t.\t22\n"
     ]
    }
   ],
   "source": [
    "!head -20 {read_files[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines processed\n",
      "1000000 lines processed\n",
      "2000000 lines processed\n",
      "3000000 lines processed\n",
      "4000000 lines processed\n",
      "5000000 lines processed\n",
      "6000000 lines processed\n",
      "7000000 lines processed\n",
      "8000000 lines processed\n",
      "9000000 lines processed\n",
      "10000000 lines processed\n",
      "11000000 lines processed\n",
      "12000000 lines processed\n",
      "13000000 lines processed\n",
      "14000000 lines processed\n",
      "15000000 lines processed\n",
      "16000000 lines processed\n",
      "17000000 lines processed\n",
      "18000000 lines processed\n",
      "19000000 lines processed\n",
      "20000000 lines processed\n",
      "21000000 lines processed\n",
      "22000000 lines processed\n",
      "23000000 lines processed\n",
      "24000000 lines processed\n",
      "25000000 lines processed\n",
      "26000000 lines processed\n",
      "27000000 lines processed\n",
      "28000000 lines processed\n",
      "29000000 lines processed\n",
      "30000000 lines processed\n",
      "31000000 lines processed\n",
      "32000000 lines processed\n",
      "33000000 lines processed\n",
      "34000000 lines processed\n",
      "35000000 lines processed\n",
      "36000000 lines processed\n",
      "37000000 lines processed\n",
      "38000000 lines processed\n",
      "39000000 lines processed\n",
      "40000000 lines processed\n",
      "41000000 lines processed\n",
      "42000000 lines processed\n",
      "43000000 lines processed\n",
      "44000000 lines processed\n",
      "45000000 lines processed\n",
      "46000000 lines processed\n",
      "47000000 lines processed\n",
      "48000000 lines processed\n",
      "49000000 lines processed\n",
      "50000000 lines processed\n",
      "51000000 lines processed\n",
      "52000000 lines processed\n",
      "53000000 lines processed\n",
      "54000000 lines processed\n",
      "55000000 lines processed\n",
      "56000000 lines processed\n",
      "57000000 lines processed\n",
      "58000000 lines processed\n",
      "59000000 lines processed\n",
      "60000000 lines processed\n",
      "61000000 lines processed\n",
      "62000000 lines processed\n",
      "63000000 lines processed\n",
      "64000000 lines processed\n",
      "65000000 lines processed\n",
      "66000000 lines processed\n",
      "67000000 lines processed\n",
      "68000000 lines processed\n",
      "69000000 lines processed\n",
      "70000000 lines processed\n",
      "71000000 lines processed\n",
      "72000000 lines processed\n",
      "73000000 lines processed\n",
      "74000000 lines processed\n",
      "75000000 lines processed\n",
      "76000000 lines processed\n",
      "77000000 lines processed\n",
      "78000000 lines processed\n",
      "79000000 lines processed\n",
      "80000000 lines processed\n",
      "81000000 lines processed\n",
      "82000000 lines processed\n",
      "83000000 lines processed\n",
      "84000000 lines processed\n",
      "85000000 lines processed\n",
      "86000000 lines processed\n",
      "87000000 lines processed\n",
      "88000000 lines processed\n",
      "89000000 lines processed\n",
      "90000000 lines processed\n",
      "91000000 lines processed\n",
      "92000000 lines processed\n",
      "93000000 lines processed\n",
      "94000000 lines processed\n",
      "95000000 lines processed\n",
      "96000000 lines processed\n",
      "97000000 lines processed\n",
      "98000000 lines processed\n",
      "99000000 lines processed\n",
      "100000000 lines processed\n",
      "101000000 lines processed\n",
      "102000000 lines processed\n",
      "103000000 lines processed\n",
      "104000000 lines processed\n",
      "105000000 lines processed\n",
      "106000000 lines processed\n",
      "107000000 lines processed\n",
      "108000000 lines processed\n",
      "109000000 lines processed\n",
      "110000000 lines processed\n",
      "111000000 lines processed\n",
      "112000000 lines processed\n",
      "113000000 lines processed\n",
      "114000000 lines processed\n",
      "115000000 lines processed\n",
      "116000000 lines processed\n",
      "117000000 lines processed\n",
      "118000000 lines processed\n",
      "119000000 lines processed\n",
      "120000000 lines processed\n",
      "121000000 lines processed\n",
      "122000000 lines processed\n",
      "123000000 lines processed\n",
      "124000000 lines processed\n",
      "125000000 lines processed\n",
      "126000000 lines processed\n",
      "127000000 lines processed\n"
     ]
    }
   ],
   "source": [
    "## testing out method...\n",
    "intermediate_outdir = safe_makedir('/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210325_GoM_recluster_analysis/GORG_recruitment_mmseq_clusts3')\n",
    "#final_outdir = safe_makedir(\"/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210325_GoM_recluster_analysis/GORG_recruitment/MMseq_cluster_summaries\")\n",
    "\n",
    "columns=['genus',\n",
    "        'ec_number', \n",
    "        'prokka_function',\n",
    "        'prokka_gene',\n",
    "        'seq_ids_lca',\n",
    "        'exclusive',\n",
    "        'shared',\n",
    "        'gene_clusters',\n",
    "        'gene_clusters_hit_count']\n",
    "\n",
    "for infile in read_files[:1]:\n",
    "    \n",
    "    inid = op.basename(infile).split(\".\")[0]\n",
    "    \n",
    "    #final_gc_outfile = op.join(final_outdir, '{}_reads_by_gen_ko_and_gene_clust.csv'.format(inid))\n",
    "    \n",
    "    #if op.exists(final_gc_outfile):\n",
    "    #    print(\"output for {infile} already exists, output found at {final_outfile}\".format(infile=infile, final_outfile=final_outfile))\n",
    "    #    continue\n",
    "    #else:\n",
    "    reads = 0\n",
    "    recorded = 0\n",
    "    with open(infile) as ih:\n",
    "\n",
    "        outfiles = []\n",
    "        if op.exists(intermediate_outdir):\n",
    "            !rm -rf {op.join(intermediate_outdir, inid)}\n",
    "\n",
    "        outdir = safe_makedir(op.join(intermediate_outdir, inid))\n",
    "\n",
    "        for j, l in enumerate(ih):\n",
    "\n",
    "            if j == 0:\n",
    "                cids = l.strip().split(\"\\t\")\n",
    "\n",
    "            if l.startswith('C'):\n",
    "                reads += 1\n",
    "                toks = dict(zip(cids, l.strip().split(\"\\t\")))\n",
    "                nodes_hit = toks['sequence_ids_lca'][:-1].split(\",\")\n",
    "                \n",
    "                labels = [d2[i] for i in nodes_hit]\n",
    "                gens = [i.split(\"--\")[-1] for i in labels]\n",
    "                gene_clusters = \",\".join(list(set([i.split(\"--\")[0] for i in labels])))\n",
    "\n",
    "                if len(gens) == 0:\n",
    "                    keep = l\n",
    "                    break\n",
    "\n",
    "                if len(set(gens)) > 1:\n",
    "                    category = 'shared'\n",
    "                    shared = 1\n",
    "                    exclusive=0\n",
    "                else:\n",
    "                    category = 'exclusive'\n",
    "                    exclusive = 1\n",
    "                    shared = 0\n",
    "\n",
    "                for gen in list(set(gens)):\n",
    "                    recorded += 1\n",
    "                    outfile = op.join(outdir, \"{}.tsv\".format(gen))\n",
    "                    if not op.exists(outfile):\n",
    "                        outfiles.append(outfile)\n",
    "                        with open(outfile, \"w\") as oh:\n",
    "                            print(\"\\t\".join(columns), file = oh)\n",
    "                            print(gen, toks['ec_number'], toks['prokka_function'], toks['prokka_gene'], toks['sequence_ids_lca'], exclusive, shared, gene_clusters, sep=\"\\t\", file = oh)\n",
    "                    else:\n",
    "                        with open(outfile, \"a\") as oh:\n",
    "                            print(gen, toks['ec_number'], toks['prokka_function'], toks['prokka_gene'], toks['sequence_ids_lca'], exclusive, shared, gene_clusters, sep=\"\\t\", file = oh)\n",
    "            if j % 1000000 == 0:\n",
    "                print(j, 'lines processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to group/count/summarise results, do something like this...\n",
    "\n",
    "intermediate_outdir = '/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210325_GoM_recluster_analysis/GORG_recruitment_mmseq_clusts3'\n",
    "#final_outdir = safe_makedir(\"/mnt/scgc/simon/microg2p/analyses/20210325_GoM_recluster/20210325_GoM_recluster_analysis/GORG_recruitment/MMseq_cluster_summaries\")\n",
    "\n",
    "\n",
    "for infile in read_files:\n",
    "    inid = op.basename(infile).split(\".\")[0]\n",
    "    \n",
    "    outdir = op.join(intermediate_outdir, inid)\n",
    "    outfiles = glob.glob(op.join(outdir, '*.tsv'))\n",
    "    outdf = pd.concat([pd.read_csv(i, sep = \"\\t\") for i in outfiles]).groupby(['genus','gene_clusters'], \n",
    "                                                                              as_index=False)['ec_number'].count().rename(columns={'ec_number':'reads_hit'}).sort_values(by='reads_hit', ascending=False)\n",
    "    outdf['read_library'] = inid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
